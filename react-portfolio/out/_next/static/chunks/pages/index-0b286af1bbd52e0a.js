(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[405],{5557:function(e,n,i){(window.__NEXT_P=window.__NEXT_P||[]).push(["/",function(){return i(6419)}])},6419:function(e,n,i){"use strict";i.r(n),i.d(n,{default:function(){return N}});var t=i(5893),a=i(9008),s=i.n(a),o=i(9815),l=i(7294),r=i(9009);i(9675);var c={publications:[],projects:[{title:"Financial Market Prediction",link:"https://example.com/financial-market-prediction",content:"Developing a Finance-Informed Neural Network for predicting SPY S&P 500 stock prices using time-series data. Leveraging FinBERT for advanced sentiment analysis of financial news, earnings reports, and market sentiment to improve prediction accuracy. This project combines deep learning techniques with financial domain knowledge to create more accurate market predictions.",slug:"financial-market-prediction"},{title:"Formation Control and Multi-Agent Pathfinding (MAPF)",link:"https://example.com/formation-control-mapf",content:"Developed GIF-PIBT, a cutting-edge algorithm that integrates global formation heuristics with the Priority Inheritance with Backtracking (PIBT) framework to maintain agent formations while ensuring scalable, collision-free pathfinding. Developed a multi-resolution grid system and formation-maintenance heuristic using cost functions and transformations, optimizing transitions between formation-based and individual strategies in dynamic, obstacle-rich environments.",slug:"formation-control-mapf"},{title:"House Inspection Automation",link:"https://example.com/house-inspection-automation",content:"Developed a comprehensive image-processing pipeline leveraging classical and deep learning methods to detect structural damages such as rust, cracks, and wear in property images, enabling automated and reliable inspection reports. Engineered a modular system integrating semantic segmentation and contour-based algorithms for damage localization and classification, ensuring adaptability across diverse lighting and material conditions.",slug:"house-inspection-automation"},{title:"Qualitative Analysis of RL Algorithms in Various Gym Environments",link:"https://example.com/rl-algorithms-analysis",content:"Applied SARSA, Q-learning, and Dueling DQN across diverse environments, including Acrobot, Cartpole, and Taxi-v3. Leveraged advanced techniques like Monte-Carlo REINFORCE, SMDP-Q, and Dyna-Q in various gym environments. This project provided comprehensive analysis and comparison of different reinforcement learning algorithms across multiple benchmark environments.",slug:"rl-algorithms-analysis"}],awards:[],hero:{name:"Gopalakrishnan Thirunellai Venkitachalam",title:"Master's of Science, AI & Robotics Research",institution:"Robotics Institute, Carnegie Mellon University",tagline:"Advancing motion planning and multi-agent systems through algorithmic innovation",profile_initials:"GV",profile_image:"profile.jpeg",email:"gopalakt@andrew.cmu.edu",phone:"+1 (412) 909-7233",github:"https://github.com/PegasusGTV",linkedin:"https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam",scholar:"",resume:"",content:"## Social Links\n\n- **Email**: [gopalakt@andrew.cmu.edu](mailto:gopalakt@andrew.cmu.edu)\n- **Phone**: [+1 (412) 909-7233](tel:+14129097233)\n- **LinkedIn**: [LinkedIn Profile](https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam)\n- **GitHub**: [GitHub Profile](https://github.com/PegasusGTV)\n\n## Background Elements\n\n- Background pattern with gradient circles\n- Scroll down indicator with animated arrow\n- Profile image placeholder with initials"},about:{title:"About Me",current_position:"Graduate Research Assistant at Search Based Planning Lab, Robotics Institute, CMU",advisor:"Prof. Maxim Likhachev",previous_position:"Research Intern in ML, Control, and Data Analytics at Caterpillar Inc.",education:"B.Tech in Mechanical Engineering with Honors from IIT Madras",achievement:"GPA 4.0/4.0 at CMU, GPA 8.71/10.0 at IIT Madras",content:"## About Me\n\nHello! I'm Gopalakrishnan Thirunellai Venkitachalam (Gopal), a Master's student in AI & Robotics Research, Mechanical Engineering at [Carnegie Mellon University](https://www.cmu.edu/). I'm currently working as a Graduate Research Assistant at the [Search Based Planning Lab](https://www.cs.cmu.edu/~maxim/), [Robotics Institute](https://www.ri.cmu.edu/), under the guidance of [Prof. Maxim Likhachev](https://www.cs.cmu.edu/~maxim/).\n\nMy research focuses on developing efficient motion planning algorithms for robotics applications, with particular emphasis on real-time planning for mobile manipulators and multi-agent systems.\n\n---\n\n## Current Research\n\n\uD83D\uDD2C **Constant Time Motion Planning (CTMP) for Mobile Manipulators**  \nDeveloping algorithms for optimizing dynamic task allocation and motion planning in warehouse robotics. Implementing solutions in C++ & ROS to enhance real-time adaptability and execution efficiency. Working on simulated door-opening tasks with Ridgeback UR10e teleoperation in SAPien and Maniskill, demonstrating precision for hazardous applications like nuclear waste disposal.\n\n---\n\n## Education\n\n\uD83C\uDF93 **Master's of Science, AI & Robotics Research, Mechanical Engineering**  \n[Carnegie Mellon University](https://www.cmu.edu/), Pittsburgh, PA  \n*May 2026 (Expected)* | GPA: 4.0/4.0\n\n**Relevant Courses**: Deep Learning, Planning & Decision-Making, Computer Vision for Robotics, Modern Control Theory\n\n---\n\n\uD83C\uDF93 **Bachelor of Technology in Mechanical Engineering with Honors**  \n[Indian Institute of Technology Madras](https://www.iitm.ac.in/), Chennai, India  \n*June 2024* | GPA: 8.71/10.0 | Minor in Artificial Intelligence and Machine Learning\n\n**Relevant Courses**: Machine Learning, Reinforcement Learning, Deep Learning, Multi-Armed Bandits, Field and Service Robotics, Multi-Body Dynamics, Stochastic Processes, Signal Processing, Control of Automotive Systems, Design and Optimization\n\n---\n\n## Work Experience\n\n\uD83D\uDCDA **Graduate Research Assistant** — [Search Based Planning Lab](https://www.cs.cmu.edu/~maxim/), Robotics Institute, CMU  \n*September 2024 – Present* | Advisor: [Prof. Maxim Likhachev](https://www.cs.cmu.edu/~maxim/)\n\n- Developing Constant Time Motion Planning (CTMP) algorithms for mobile manipulators\n- Optimizing dynamic task allocation and motion planning in warehouse robotics\n- Implementing solutions in C++ & ROS for real-time adaptability\n- Simulating door-opening tasks with Ridgeback UR10e teleoperation in SAPien and Maniskill\n\n---\n\n\uD83C\uDFED **Research Intern in ML, Control, and Data Analytics** — [Caterpillar Inc.](https://www.caterpillar.com/)  \n*May 2023 – January 2024* | Chennai, India\n\n- Developed MATLAB and Simulink models for predicting diesel engine exhaust gas temperature dynamics\n- Implemented Python scripts for cleaning and analyzing large-scale engine datasets using PCA and K-means clustering\n- Designed data visualization dashboard with Plotly for spectral and operational cycle analysis\n\n---\n\n## Technical Skills\n\n**Programming Languages**: C++, Python, C, MATLAB & Simulink, Linux, Git\n\n**Frameworks & Tools**: PyTorch, TensorFlow, Scikit-learn, OpenCV, MoveIt, ROS, Pandas, NumPy, SymPy, Vaex\n\n**Areas of Expertise**: Machine Learning, Deep Learning, Reinforcement Learning, Motion Planning, Computer Vision, Control Systems\n\n---\n\n## \uD83D\uDD2D Research Interests\n\nMy research interests span motion planning, multi-agent systems, machine learning, and robotics. I'm particularly interested in developing efficient algorithms that can operate in real-time for practical robotic applications, including warehouse automation, hazardous environment operations, and multi-agent coordination.\n\n---\n\n## Research Statistics\n\n- **Current GPA**: 4.0/4.0 (CMU)\n- **Research Experience**: 2+ years\n- **Industry Experience**: 1+ year"},contact:{title:"Get In Touch",description:"I'm always interested in discussing new research opportunities, collaborations, and innovative projects in AI, robotics, and motion planning.",primary_cta:"Send me an email",primary_cta_link:"mailto:gopalakt@andrew.cmu.edu",content:"## Contact Information\n\n### Email\n- **Type**: Email\n- **Value**: gopalakt@andrew.cmu.edu\n- **Link**: mailto:gopalakt@andrew.cmu.edu\n\n### Phone\n- **Type**: Phone\n- **Value**: +1 (412) 909-7233\n- **Link**: tel:+14129097233\n\n### LinkedIn\n- **Type**: LinkedIn\n- **Value**: Connect\n- **Link**: https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam\n\n### GitHub\n- **Type**: GitHub\n- **Value**: View Profile\n- **Link**: https://github.com/PegasusGTV"},interests:{title:"Research Interests",description:"My research focuses on motion planning, multi-agent systems, machine learning, and robotics, with emphasis on real-time algorithms for practical applications including warehouse automation and hazardous environment operations.",content:"## Interest Areas\n\n### Motion Planning\n- **Description**: Developing efficient algorithms for real-time motion planning in robotics, including constant-time planning (CTMP) for mobile manipulators, pathfinding in complex environments, and dynamic task allocation for warehouse robotics applications.\n- **Icon**: \uD83D\uDDFA️\n\n### Multi-Agent Systems\n- **Description**: Researching formation control, multi-agent pathfinding (MAPF), and coordination algorithms for collaborative robotic systems. Working on GIF-PIBT algorithms that integrate global formation heuristics with priority-based pathfinding frameworks.\n- **Icon**: \uD83D\uDC65\n\n### Machine Learning & Deep Learning\n- **Description**: Applying machine learning techniques including reinforcement learning, deep learning, and neural networks to solve robotics and prediction problems. Experience with PyTorch, TensorFlow, and various RL algorithms for robotic applications.\n- **Icon**: \uD83E\uDD16\n\n### Computer Vision\n- **Description**: Developing computer vision solutions for robotics applications, including object detection, semantic segmentation, and visual recognition systems. Experience with OpenCV and deep learning-based vision models.\n- **Icon**: \uD83D\uDC41️\n\n### Control Systems\n- **Description**: Designing and implementing control systems for robotic applications, including predictive control, real-time system optimization, and control of automotive systems. Experience with MATLAB, Simulink, and modern control theory.\n- **Icon**: \uD83C\uDF9B️\n\n### Data Analytics\n- **Description**: Analyzing large-scale datasets using statistical methods, PCA, K-means clustering, and visualization techniques for engineering applications. Experience with Python, Pandas, NumPy, and data visualization tools.\n- **Icon**: \uD83D\uDCCA"},research:{title:"Current Research",description:"My research focuses on developing efficient motion planning algorithms for robotics applications, with particular emphasis on real-time planning for mobile manipulators and multi-agent systems.",content:"## Current Research\n\n\uD83D\uDD2C **Constant Time Motion Planning (CTMP) for Mobile Manipulators**  \nDeveloping algorithms for optimizing dynamic task allocation and motion planning in warehouse robotics. Implementing solutions in C++ & ROS to enhance real-time adaptability and execution efficiency. Working on simulated door-opening tasks with Ridgeback UR10e teleoperation in SAPien and Maniskill, demonstrating precision for hazardous applications like nuclear waste disposal.\n\n## Research Focus Areas\n\n### Motion Planning\n- Real-time motion planning for mobile manipulators\n- Constant-time planning algorithms\n- Pathfinding in complex, dynamic environments\n- Warehouse robotics automation\n\n### Multi-Agent Systems\n- Formation control algorithms\n- Multi-agent pathfinding (MAPF)\n- Coordination strategies for collaborative systems\n- Dynamic task allocation\n\n### Machine Learning Applications\n- Reinforcement learning for robotics\n- Deep learning for motion prediction\n- Neural network-based planning strategies\n\n## Research Environment\n\n- **Laboratory**: Search Based Planning Lab, Robotics Institute, CMU\n- **Advisor**: Prof. Maxim Likhachev\n- **Tools & Technologies**: C++, ROS, SAPien, Maniskill, Python, PyTorch\n- **Applications**: Warehouse automation, hazardous environment operations, nuclear waste disposal"},navbar:{title:"Navigation",content:"## Navigation Items\n\n- **About**: #about\n- **Research**: #research\n- **Projects**: #projects\n- **Contact**: #contact\n\n## Mobile Menu\n- Responsive mobile menu with hamburger icon\n- Smooth scroll to sections\n- Auto-close on navigation"},footer:{copyright_text:"\xa9 2024 Gopalakrishnan Thirunellai Venkitachalam. All rights reserved.",content:"## Social Links\n\n### Email\n- **Link**: mailto:gopalakt@andrew.cmu.edu\n- **Aria Label**: Email\n\n### GitHub\n- **Link**: https://github.com/PegasusGTV\n- **Aria Label**: GitHub\n\n### LinkedIn\n- **Link**: https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam\n- **Aria Label**: LinkedIn\n\n## Footer Features\n- Dynamic year calculation\n- Hover animations\n- Responsive layout"}},d=function(e){return c[e]||[]},m=function(e){return c[e]||null},h=function(){var e=(0,l.useState)(!1),n=e[0],i=e[1],a=(0,l.useState)(!1),s=a[0],c=a[1];m("navbar");var h=d("publications"),u=d("awards");(0,l.useEffect)(function(){var e=function(){i(window.scrollY>50)};return window.addEventListener("scroll",e),function(){return window.removeEventListener("scroll",e)}},[]);var p=[{name:"About",href:"#about"},{name:"Research",href:"#research"},].concat((0,o.Z)(h.length>0?[{name:"Publications",href:"#publications"}]:[]),[{name:"Projects",href:"#projects"},],(0,o.Z)(u.length>0?[{name:"Awards",href:"#awards"}]:[]),[{name:"Contact",href:"#contact"},]),x=function(e){var n=document.querySelector(e);n&&n.scrollIntoView({behavior:"smooth"}),c(!1)};return(0,t.jsxs)(r.E.nav,{initial:{y:-100},animate:{y:0},className:"fixed top-0 left-0 right-0 z-50 transition-all duration-300 ".concat(n?"bg-navy/90 backdrop-blur-md":"bg-transparent"),children:[(0,t.jsx)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:(0,t.jsxs)("div",{className:"flex items-center justify-between h-16",children:[(0,t.jsx)(r.E.div,{whileHover:{scale:1.05},className:"flex-shrink-0",children:(0,t.jsx)("span",{className:"text-xl font-bold text-accent",children:"GV"})}),(0,t.jsx)("div",{className:"hidden md:block",children:(0,t.jsx)("div",{className:"ml-10 flex items-baseline space-x-8",children:p.map(function(e){return(0,t.jsx)(r.E.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:function(){return x(e.href)},className:"text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200",children:e.name},e.name)})})}),(0,t.jsx)("div",{className:"md:hidden",children:(0,t.jsx)(r.E.button,{whileTap:{scale:.95},onClick:function(){return c(!s)},className:"text-lightSlate hover:text-accent p-2",children:(0,t.jsx)("svg",{className:"h-6 w-6",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:s?(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M6 18L18 6M6 6l12 12"}):(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M4 6h16M4 12h16M4 18h16"})})})})]})}),s&&(0,t.jsx)(r.E.div,{initial:{opacity:0,height:0},animate:{opacity:1,height:"auto"},exit:{opacity:0,height:0},className:"md:hidden bg-navy/95 backdrop-blur-md",children:(0,t.jsx)("div",{className:"px-2 pt-2 pb-3 space-y-1 sm:px-3",children:p.map(function(e){return(0,t.jsx)(r.E.button,{whileHover:{scale:1.05},whileTap:{scale:.95},onClick:function(){return x(e.href)},className:"text-lightSlate hover:text-accent block px-3 py-2 text-base font-medium w-full text-left",children:e.name},e.name)})})})]})},u=function(){var e=(0,l.useState)(!1),n=e[0],i=e[1],a=(0,l.useState)(null),s=a[0],o=a[1];(0,l.useEffect)(function(){i(!0),o(m("hero"))},[]);var c=function(){var e=document.querySelector("#about");e&&e.scrollIntoView({behavior:"smooth"})};return(0,t.jsxs)("section",{className:"min-h-screen flex items-center justify-center relative overflow-hidden",children:[(0,t.jsxs)("div",{className:"absolute inset-0 opacity-10",children:[(0,t.jsx)("div",{className:"absolute top-1/4 left-1/4 w-64 h-64 bg-accent rounded-full blur-3xl"}),(0,t.jsx)("div",{className:"absolute bottom-1/4 right-1/4 w-96 h-96 bg-accent rounded-full blur-3xl"})]}),(0,t.jsx)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center relative z-10",children:(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:n?1:0,y:n?0:30},transition:{duration:.8},className:"space-y-8",children:[(0,t.jsx)(r.E.div,{initial:{scale:0},animate:{scale:n?1:0},transition:{duration:.8,delay:.2},className:"w-32 h-32 mx-auto rounded-full overflow-hidden border-4 border-accent shadow-lg",children:(null==s?void 0:s.profile_image)?(0,t.jsx)("img",{src:"/".concat(s.profile_image),alt:(null==s?void 0:s.name)||"Profile",className:"w-full h-full object-cover"}):(0,t.jsx)("div",{className:"w-full h-full bg-gradient-to-br from-accent to-accent/50 flex items-center justify-center text-4xl font-bold text-navy",children:(null==s?void 0:s.profile_initials)||"GV"})}),(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:n?1:0,y:n?0:20},transition:{duration:.8,delay:.4},className:"space-y-4",children:[(0,t.jsx)("h1",{className:"text-4xl md:text-6xl lg:text-7xl font-bold text-white",children:(null==s?void 0:s.name)||"Gopalakrishnan Thirunellai Venkitachalam"}),(0,t.jsxs)("p",{className:"text-xl md:text-2xl lg:text-3xl text-accent font-medium",children:[(null==s?void 0:s.title)||"Master's of Science, AI & Robotics Research",(0,t.jsx)("br",{}),(null==s?void 0:s.institution)||"Robotics Institute, Carnegie Mellon University"]}),(0,t.jsx)("p",{className:"text-lg md:text-xl text-lightSlate max-w-3xl mx-auto",children:(null==s?void 0:s.tagline)||"Advancing motion planning and multi-agent systems through algorithmic innovation"})]}),(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:n?1:0,y:n?0:20},transition:{duration:.8,delay:.6},className:"flex flex-wrap justify-center gap-6",children:[(0,t.jsxs)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:"mailto:".concat((null==s?void 0:s.email)||"gopalakt@andrew.cmu.edu"),className:"flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200",children:[(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"})}),(0,t.jsx)("span",{children:"Email"})]}),(null==s?void 0:s.github)&&(0,t.jsxs)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:s.github,target:"_blank",rel:"noopener noreferrer",className:"flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200",children:[(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"})}),(0,t.jsx)("span",{children:"GitHub"})]}),(null==s?void 0:s.linkedin)&&(0,t.jsxs)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:s.linkedin,target:"_blank",rel:"noopener noreferrer",className:"flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200",children:[(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"})}),(0,t.jsx)("span",{children:"LinkedIn"})]})]}),(0,t.jsx)(r.E.div,{initial:{opacity:0},animate:{opacity:n?1:0},transition:{duration:.8,delay:.8},className:"pt-8",children:(0,t.jsx)(r.E.button,{whileHover:{y:-5},onClick:c,className:"text-accent hover:text-white transition-colors duration-200",children:(0,t.jsxs)("div",{className:"flex flex-col items-center space-y-2",children:[(0,t.jsx)("span",{className:"text-sm",children:"Scroll Down"}),(0,t.jsx)(r.E.div,{animate:{y:[0,5,0]},transition:{duration:1.5,repeat:1/0},children:(0,t.jsx)("svg",{className:"w-6 h-6",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M19 14l-7 7m0 0l-7-7m7 7V3"})})})]})})})]})})]})},p=i(828),x=i(1799),g=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},n=(0,l.useRef)(null),i=(0,l.useState)(!1),t=i[0],a=i[1];return(0,l.useEffect)(function(){var i=new IntersectionObserver(function(e){(0,p.Z)(e,1)[0].isIntersecting&&a(!0)},(0,x.Z)({threshold:e.threshold||.1,rootMargin:e.margin||"0px"},e));return n.current&&i.observe(n.current),function(){return i.disconnect()}},[e.threshold,e.margin]),[n,t]},v=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=m("about");return(0,t.jsx)("section",{id:"about",ref:n,className:"py-20 bg-lightNavy/30",children:(0,t.jsx)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"max-w-4xl mx-auto text-center",children:[(0,t.jsx)("h2",{className:"section-title",children:(null==a?void 0:a.title)||"About Me"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("div",{className:"space-y-6 text-lg text-lightSlate leading-relaxed",children:(null==a?void 0:a.content)?(0,t.jsx)("div",{dangerouslySetInnerHTML:{__html:a.content.replace(/\n\n/g,"</p><p>").replace(/^/,"<p>").replace(/$/,"</p>")}}):(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)("p",{children:"Hello! I'm Gopalakrishnan Thirunellai Venkitachalam (Gopal), a Master's student in AI & Robotics Research, Mechanical Engineering at Carnegie Mellon University. I'm currently working as a Graduate Research Assistant at the Search Based Planning Lab, Robotics Institute, under the guidance of Prof. Maxim Likhachev."}),(0,t.jsx)("p",{children:"My research focuses on developing efficient motion planning algorithms for robotics applications, with particular emphasis on real-time planning for mobile manipulators and multi-agent systems."}),(0,t.jsx)("p",{children:"Previously, I was a Research Intern in ML, Control, and Data Analytics at Caterpillar Inc., where I developed MATLAB and Simulink models for predicting diesel engine exhaust gas temperature dynamics."}),(0,t.jsx)("p",{children:"I hold a B.Tech in Mechanical Engineering with Honors from IIT Madras, with a Minor in Artificial Intelligence and Machine Learning, achieving a GPA of 8.71/10.0."})]})}),(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:i?1:0,y:i?0:20},transition:{duration:.8,delay:.3},className:"grid grid-cols-1 md:grid-cols-3 gap-8 mt-16",children:[(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-3xl font-bold text-accent mb-2",children:"4.0"}),(0,t.jsx)("div",{className:"text-lightSlate",children:"GPA at CMU"})]}),(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-3xl font-bold text-accent mb-2",children:"2+"}),(0,t.jsx)("div",{className:"text-lightSlate",children:"Years Research Experience"})]}),(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-3xl font-bold text-accent mb-2",children:"1+"}),(0,t.jsx)("div",{className:"text-lightSlate",children:"Year Industry Experience"})]})]})]})})})},f=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=m("interests"),s=function(e){if(!e)return[];var n=[];return e.split(/### /).filter(function(e){return e.trim()}).forEach(function(e){var i=e.split("\n").filter(function(e){return e.trim()});if(0!==i.length){var t=i[0].trim(),a="",s="\uD83D\uDD2C";i.forEach(function(e){e.includes("**Description**:")&&(a=e.replace(/\*\*Description\*\*:\s*/,"").trim()),e.includes("**Icon**:")&&(s=e.replace(/\*\*Icon\*\*:\s*/,"").trim())}),t&&a&&n.push({title:t,description:a,icon:s})}}),n}(null==a?void 0:a.content)||[{title:"Motion Planning",description:"Developing efficient algorithms for real-time motion planning in robotics, including constant-time planning for mobile manipulators and pathfinding in complex environments.",icon:"\uD83D\uDDFA️"},{title:"Multi-Agent Systems",description:"Researching formation control, multi-agent pathfinding (MAPF), and coordination algorithms for collaborative robotic systems.",icon:"\uD83D\uDC65"},{title:"Machine Learning & Deep Learning",description:"Applying machine learning techniques including reinforcement learning, deep learning, and neural networks to solve robotics and prediction problems.",icon:"\uD83E\uDD16"},{title:"Computer Vision",description:"Developing computer vision solutions for robotics applications, including object detection, semantic segmentation, and visual recognition systems.",icon:"\uD83D\uDC41️"},{title:"Control Systems",description:"Designing and implementing control systems for robotic applications, including predictive control and real-time system optimization.",icon:"\uD83C\uDF9B️"},{title:"Data Analytics",description:"Analyzing large-scale datasets using statistical methods, clustering, and visualization techniques for engineering applications.",icon:"\uD83D\uDCCA"}];return(0,t.jsx)("section",{id:"research",ref:n,className:"py-20",children:(0,t.jsxs)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:[(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"text-center mb-16",children:[(0,t.jsx)("h2",{className:"section-title",children:(null==a?void 0:a.title)||"Research Interests"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("p",{className:"text-lg text-lightSlate max-w-3xl mx-auto",children:(null==a?void 0:a.description)||"My research focuses on motion planning, multi-agent systems, machine learning, and robotics, with emphasis on real-time algorithms for practical applications."})]}),(0,t.jsx)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8,delay:.2},className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8 max-w-6xl mx-auto",children:s.map(function(e,n){return(0,t.jsx)(r.E.div,{whileHover:{scale:1.05,y:-5,transition:{duration:.2}},whileTap:{scale:.95},className:"card group cursor-pointer",children:(0,t.jsxs)("div",{className:"text-center",children:[(0,t.jsx)("div",{className:"text-4xl mb-4 group-hover:scale-110 transition-transform duration-200",children:e.icon}),(0,t.jsx)("h3",{className:"text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200",children:e.title}),(0,t.jsx)("p",{className:"text-lightSlate group-hover:text-lightestSlate transition-colors duration-200",children:e.description})]})},n)})})]})})},y=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=d("publications");return 0===a.length?null:(0,t.jsx)("section",{id:"publications",ref:n,className:"py-20 bg-lightNavy/30",children:(0,t.jsxs)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:[(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"text-center mb-16",children:[(0,t.jsx)("h2",{className:"section-title",children:"Publications"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("p",{className:"text-lg text-lightSlate max-w-3xl mx-auto",children:"My research contributions in multi-agent reinforcement learning, robotics, and AI systems."})]}),(0,t.jsx)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8,delay:.2},className:"space-y-8",children:a.length>0?a.map(function(e,n){return(0,t.jsx)(r.E.div,{initial:{opacity:0,x:-20},animate:{opacity:i?1:0,x:i?0:-20},transition:{duration:.6,delay:.1*n},className:"card group hover:border-accent transition-all duration-300",children:(0,t.jsxs)("div",{className:"flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4",children:[(0,t.jsxs)("div",{className:"flex-1",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200",children:e.title}),(0,t.jsx)("p",{className:"text-lightSlate mb-3",children:e.authors}),(0,t.jsx)("div",{className:"flex flex-wrap items-center gap-4 text-sm",children:(0,t.jsxs)("span",{className:"bg-accent/20 text-accent px-3 py-1 rounded-full",children:[e.venue," ",e.year]})}),e.content&&(0,t.jsx)("p",{className:"text-lightSlate mt-4 leading-relaxed",children:e.content})]}),e.link&&(0,t.jsx)(r.E.a,{whileHover:{scale:1.05},whileTap:{scale:.95},href:e.link,target:"_blank",rel:"noopener noreferrer",className:"btn-primary whitespace-nowrap self-start lg:self-center",children:"Read Paper"})]})},n)}):(0,t.jsx)("div",{className:"text-center py-12",children:(0,t.jsx)("div",{className:"text-lightSlate text-lg",children:"No publications available at the moment."})})})]})})},w=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=d("projects");return(0,t.jsx)("section",{id:"projects",ref:n,className:"py-20",children:(0,t.jsxs)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:[(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"text-center mb-16",children:[(0,t.jsx)("h2",{className:"section-title",children:"Projects"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("p",{className:"text-lg text-lightSlate max-w-3xl mx-auto",children:"Selected projects showcasing my work in motion planning, robotics, machine learning, and data analytics."})]}),(0,t.jsx)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8,delay:.2},className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8",children:a.length>0?a.map(function(e,n){return(0,t.jsx)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:i?1:0,y:i?0:20},transition:{duration:.6,delay:.1*n},whileHover:{scale:1.05,y:-5,transition:{duration:.2}},className:"card group cursor-pointer",children:(0,t.jsxs)("div",{className:"h-full flex flex-col",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200",children:e.title}),e.content&&(0,t.jsx)("p",{className:"text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1",children:e.content}),e.link&&(0,t.jsxs)(r.E.a,{whileHover:{scale:1.05},whileTap:{scale:.95},href:e.link,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200",children:[(0,t.jsx)("span",{className:"mr-2",children:"View Project"}),(0,t.jsx)("svg",{className:"w-4 h-4",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"})})]})]})},n)}):(0,t.jsx)("div",{className:"col-span-full text-center py-12",children:(0,t.jsx)("div",{className:"text-lightSlate text-lg",children:"No projects available at the moment."})})})]})})},b=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=d("awards");return 0===a.length?null:(0,t.jsx)("section",{id:"awards",ref:n,className:"py-20 bg-lightNavy/30",children:(0,t.jsxs)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:[(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"text-center mb-16",children:[(0,t.jsx)("h2",{className:"section-title",children:"Awards & Recognition"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("p",{className:"text-lg text-lightSlate max-w-3xl mx-auto",children:"Recognition for academic excellence and research contributions."})]}),(0,t.jsx)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8,delay:.2},className:"max-w-4xl mx-auto",children:a.length>0?(0,t.jsxs)("div",{className:"relative",children:[(0,t.jsx)("div",{className:"absolute left-8 top-0 bottom-0 w-0.5 bg-accent/30"}),(0,t.jsx)("div",{className:"space-y-8",children:a.map(function(e,n){return(0,t.jsxs)(r.E.div,{initial:{opacity:0,x:-20},animate:{opacity:i?1:0,x:i?0:-20},transition:{duration:.6,delay:.1*n},className:"relative flex items-start",children:[(0,t.jsx)("div",{className:"absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"}),(0,t.jsx)("div",{className:"ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group",children:(0,t.jsx)("div",{className:"flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4",children:(0,t.jsxs)("div",{className:"flex-1",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200",children:e.title}),e.year&&(0,t.jsx)("div",{className:"text-accent font-medium mb-3",children:e.year}),e.content&&(0,t.jsx)("p",{className:"text-lightSlate group-hover:text-lightestSlate transition-colors duration-200",children:e.content})]})})})]},n)})})]}):(0,t.jsx)("div",{className:"text-center py-12",children:(0,t.jsx)("div",{className:"text-lightSlate text-lg",children:"No awards available at the moment."})})})]})})},j=function(){var e=(0,p.Z)(g({once:!0,margin:"-100px"}),2),n=e[0],i=e[1],a=m("contact"),s=[{type:"Email",value:(null==a?void 0:a.email)||"gopalakt@andrew.cmu.edu",href:"mailto:".concat((null==a?void 0:a.email)||"gopalakt@andrew.cmu.edu"),icon:(0,t.jsx)("svg",{className:"w-6 h-6",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M3 8l7.89 4.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"})})},{type:"Phone",value:(null==a?void 0:a.phone)||"+1 (412) 909-7233",href:"tel:".concat((null==a?void 0:a.phone)||"+14129097233"),icon:(0,t.jsx)("svg",{className:"w-6 h-6",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M3 5a2 2 0 012-2h3.28a1 1 0 01.948.684l1.498 4.493a1 1 0 01-.502 1.21l-2.257 1.13a11.042 11.042 0 005.516 5.516l1.13-2.257a1 1 0 011.21-.502l4.493 1.498a1 1 0 01.684.949V19a2 2 0 01-2 2h-1C9.716 21 3 14.284 3 6V5z"})})},{type:"GitHub",value:"PegasusGTV",href:"https://github.com/PegasusGTV",icon:(0,t.jsx)("svg",{className:"w-6 h-6",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"})})},{type:"LinkedIn",value:"Connect",href:"https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam",icon:(0,t.jsx)("svg",{className:"w-6 h-6",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"})})}];return(0,t.jsx)("section",{id:"contact",ref:n,className:"py-20",children:(0,t.jsxs)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:[(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8},className:"text-center mb-16",children:[(0,t.jsx)("h2",{className:"section-title",children:(null==a?void 0:a.title)||"Get In Touch"}),(0,t.jsx)("div",{className:"w-24 h-1 bg-accent mx-auto mb-8"}),(0,t.jsx)("p",{className:"text-lg text-lightSlate max-w-3xl mx-auto",children:(null==a?void 0:a.description)||"I'm always interested in discussing new research opportunities, collaborations, and innovative projects in AI and robotics."})]}),(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:30},animate:{opacity:i?1:0,y:i?0:30},transition:{duration:.8,delay:.2},className:"max-w-4xl mx-auto",children:[(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:s.map(function(e,n){return(0,t.jsx)(r.E.a,{whileHover:{scale:1.05,y:-5,transition:{duration:.2}},whileTap:{scale:.95},href:e.href,target:"_blank",rel:"noopener noreferrer",className:"card group cursor-pointer text-center hover:border-accent transition-all duration-300",children:(0,t.jsxs)("div",{className:"flex flex-col items-center space-y-4",children:[(0,t.jsx)("div",{className:"text-accent group-hover:text-white transition-colors duration-200",children:e.icon}),(0,t.jsxs)("div",{children:[(0,t.jsx)("h3",{className:"text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200",children:e.type}),(0,t.jsx)("p",{className:"text-lightSlate group-hover:text-lightestSlate transition-colors duration-200",children:e.value})]})]})},n)})}),(0,t.jsx)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:i?1:0,y:i?0:20},transition:{duration:.8,delay:.4},className:"text-center mt-12",children:(0,t.jsx)(r.E.a,{whileHover:{scale:1.05},whileTap:{scale:.95},href:(null==a?void 0:a.primary_cta_link)||"mailto:gopalakt@andrew.cmu.edu",className:"btn-primary text-lg px-8 py-4",children:(null==a?void 0:a.primary_cta)||"Send me an email"})})]})]})})},k=function(){var e=new Date().getFullYear(),n=m("footer");return(0,t.jsx)("footer",{className:"bg-navy border-t border-lightestNavy",children:(0,t.jsx)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8",children:(0,t.jsx)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.8},className:"text-center",children:(0,t.jsxs)("div",{className:"flex flex-col md:flex-row items-center justify-between space-y-4 md:space-y-0",children:[(0,t.jsx)("div",{className:"text-lightSlate",children:(null==n?void 0:n.copyright_text)||"\xa9 ".concat(e," Gopalakrishnan Thirunellai Venkitachalam. All rights reserved.")}),(0,t.jsxs)("div",{className:"flex items-center space-x-6",children:[(null==n?void 0:n.scholar)&&(0,t.jsx)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:n.scholar,target:"_blank",rel:"noopener noreferrer",className:"text-lightSlate hover:text-accent transition-colors duration-200","aria-label":"Google Scholar",children:(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"})})}),(0,t.jsx)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:"https://github.com/PegasusGTV",target:"_blank",rel:"noopener noreferrer",className:"text-lightSlate hover:text-accent transition-colors duration-200","aria-label":"GitHub",children:(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"})})}),(0,t.jsx)(r.E.a,{whileHover:{scale:1.1,y:-2},whileTap:{scale:.95},href:"https://www.linkedin.com/in/gopalakrishnan-thirunellai-venkitachalam",target:"_blank",rel:"noopener noreferrer",className:"text-lightSlate hover:text-accent transition-colors duration-200","aria-label":"LinkedIn",children:(0,t.jsx)("svg",{className:"w-5 h-5",fill:"currentColor",viewBox:"0 0 24 24",children:(0,t.jsx)("path",{d:"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"})})})]})]})})})})};function N(){return(0,t.jsxs)("div",{className:"min-h-screen bg-navy",children:[(0,t.jsxs)(s(),{children:[(0,t.jsx)("title",{children:"Gopalakrishnan Thirunellai Venkitachalam - Research Portfolio"}),(0,t.jsx)("meta",{name:"description",content:"Graduate Researcher in AI & Robotics Research at Carnegie Mellon University"}),(0,t.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),(0,t.jsx)("link",{rel:"icon",href:"/favicon.ico"})]}),(0,t.jsx)(h,{}),(0,t.jsxs)("main",{children:[(0,t.jsx)(u,{}),(0,t.jsx)(v,{}),(0,t.jsx)(f,{}),(0,t.jsx)(y,{}),(0,t.jsx)(w,{}),(0,t.jsx)(b,{}),(0,t.jsx)(j,{})]}),(0,t.jsx)(k,{})]})}},3596:function(){}},function(e){e.O(0,[146,355,774,888,179],function(){return e(e.s=5557)}),_N_E=e.O()}]);