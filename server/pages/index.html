<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="keywords" content="AI, Machine Learning, Robotics, Multi-Agent Systems, Reinforcement Learning"/><meta name="author" content="Karan Mirakhor"/><meta property="og:title" content="Karan Mirakhor - Research Portfolio"/><meta property="og:description" content="Graduate Researcher in Reinforcement Learning and Robotics at Carnegie Mellon University"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Karan Mirakhor - Research Portfolio"/><meta name="twitter:description" content="Graduate Researcher in Reinforcement Learning and Robotics at Carnegie Mellon University"/><link rel="icon" href="/favicon.ico"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"/><title>Gopalakrishnan Thirunellai Venkitachalam - Research Portfolio</title><meta name="description" content="Graduate Researcher in AI &amp; Robotics Research at Carnegie Mellon University"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="16"/><link rel="preload" href="/karan-mirakhor/_next/static/css/c903f47fc2c92de8.css" as="style"/><link rel="stylesheet" href="/karan-mirakhor/_next/static/css/c903f47fc2c92de8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/karan-mirakhor/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/karan-mirakhor/_next/static/chunks/webpack-62cf374d0e243055.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/framework-02398e00071ab346.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/main-1a56076923beba60.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/pages/_app-2f5ed480144c0cde.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/9f96d65d-4b4b53fe89d86bd7.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/264-04f9ad717ca24e12.js" defer=""></script><script src="/karan-mirakhor/_next/static/chunks/pages/index-592790ef3e560a0f.js" defer=""></script><script src="/karan-mirakhor/_next/static/oCC-3wu0cex69U6BoWB_6/_buildManifest.js" defer=""></script><script src="/karan-mirakhor/_next/static/oCC-3wu0cex69U6BoWB_6/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen bg-navy"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent" style="transform:translateY(-100px) translateZ(0)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><span class="text-xl font-bold text-accent">KM</span></div><div class="hidden md:block"><div class="ml-10 flex items-baseline space-x-8"><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">About</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Research</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Publications</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Projects</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Awards</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Contact</button></div></div><div class="md:hidden"><button class="text-lightSlate hover:text-accent p-2"><svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></div></nav><main><section class="min-h-screen flex items-center justify-center relative overflow-hidden"><div class="absolute inset-0 opacity-10"><div class="absolute top-1/4 left-1/4 w-64 h-64 bg-accent rounded-full blur-3xl"></div><div class="absolute bottom-1/4 right-1/4 w-96 h-96 bg-accent rounded-full blur-3xl"></div></div><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center relative z-10"><div class="space-y-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="w-32 h-32 mx-auto rounded-full bg-gradient-to-br from-accent to-accent/50 flex items-center justify-center text-4xl font-bold text-navy" style="transform:scale(0) translateZ(0)">KM</div><div class="space-y-4" style="opacity:0;transform:translateY(20px) translateZ(0)"><h1 class="text-4xl md:text-6xl lg:text-7xl font-bold text-white">Karan Mirakhor</h1><p class="text-xl md:text-2xl lg:text-3xl text-accent font-medium">Masters of Science (Research) in Robotics<br/>Robotics Institute, Carnegie Mellon University</p><p class="text-lg md:text-xl text-lightSlate max-w-3xl mx-auto">Advancing multi-agent systems through belief modeling and strategic decision-making</p></div><div class="flex flex-wrap justify-center gap-6" style="opacity:0;transform:translateY(20px) translateZ(0)"><a href="mailto:gopalakt@andrew.cmu.edu" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"></path></svg><span>Email</span></a><a href="https://github.com/your-username" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg><span>GitHub</span></a><a href="https://www.linkedin.com/in/your-profile/" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg><span>LinkedIn</span></a></div><div class="pt-8" style="opacity:0"><button class="text-accent hover:text-white transition-colors duration-200"><div class="flex flex-col items-center space-y-2"><span class="text-sm">Scroll Down</span><div><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 14l-7 7m0 0l-7-7m7 7V3"></path></svg></div></div></button></div></div></div></section><section id="about" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="max-w-4xl mx-auto text-center" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">About Me</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><div class="space-y-6 text-lg text-lightSlate leading-relaxed"><div><p>## About Me</p><p>Hello! I'm Gopalakrishnan Thirunellai Venkitachalam (Gopal), a Master's student in AI & Robotics Research, Mechanical Engineering at [Carnegie Mellon University](https://www.cmu.edu/). I'm currently working as a Graduate Research Assistant at the [Search Based Planning Lab](https://www.cs.cmu.edu/~maxim/), [Robotics Institute](https://www.ri.cmu.edu/), under the guidance of [Prof. Maxim Likhachev](https://www.cs.cmu.edu/~maxim/).</p><p>My research focuses on developing efficient motion planning algorithms for robotics applications, with particular emphasis on real-time planning for mobile manipulators and multi-agent systems.</p><p>---</p><p>## Current Research</p><p>üî¨ **Constant Time Motion Planning (CTMP) for Mobile Manipulators**  
Developing algorithms for optimizing dynamic task allocation and motion planning in warehouse robotics. Implementing solutions in C++ & ROS to enhance real-time adaptability and execution efficiency. Working on simulated door-opening tasks with Ridgeback UR10e teleoperation in SAPien and Maniskill, demonstrating precision for hazardous applications like nuclear waste disposal.</p><p>---</p><p>## Education</p><p>üéì **Master's of Science, AI & Robotics Research, Mechanical Engineering**  
[Carnegie Mellon University](https://www.cmu.edu/), Pittsburgh, PA  
*May 2026 (Expected)* | GPA: 4.0/4.0</p><p>**Relevant Courses**: Deep Learning, Planning & Decision-Making, Computer Vision for Robotics, Modern Control Theory</p><p>---</p><p>üéì **Bachelor of Technology in Mechanical Engineering with Honors**  
[Indian Institute of Technology Madras](https://www.iitm.ac.in/), Chennai, India  
*June 2024* | GPA: 8.71/10.0 | Minor in Artificial Intelligence and Machine Learning</p><p>**Relevant Courses**: Machine Learning, Reinforcement Learning, Deep Learning, Multi-Armed Bandits, Field and Service Robotics, Multi-Body Dynamics, Stochastic Processes, Signal Processing, Control of Automotive Systems, Design and Optimization</p><p>---</p><p>## Work Experience</p><p>üìö **Graduate Research Assistant** ‚Äî [Search Based Planning Lab](https://www.cs.cmu.edu/~maxim/), Robotics Institute, CMU  
*September 2024 ‚Äì Present* | Advisor: [Prof. Maxim Likhachev](https://www.cs.cmu.edu/~maxim/)</p><p>- Developing Constant Time Motion Planning (CTMP) algorithms for mobile manipulators
- Optimizing dynamic task allocation and motion planning in warehouse robotics
- Implementing solutions in C++ & ROS for real-time adaptability
- Simulating door-opening tasks with Ridgeback UR10e teleoperation in SAPien and Maniskill</p><p>---</p><p>üè≠ **Research Intern in ML, Control, and Data Analytics** ‚Äî [Caterpillar Inc.](https://www.caterpillar.com/)  
*May 2023 ‚Äì January 2024* | Chennai, India</p><p>- Developed MATLAB and Simulink models for predicting diesel engine exhaust gas temperature dynamics
- Implemented Python scripts for cleaning and analyzing large-scale engine datasets using PCA and K-means clustering
- Designed data visualization dashboard with Plotly for spectral and operational cycle analysis</p><p>---</p><p>## Technical Skills</p><p>**Programming Languages**: C++, Python, C, MATLAB & Simulink, Linux, Git</p><p>**Frameworks & Tools**: PyTorch, TensorFlow, Scikit-learn, OpenCV, MoveIt, ROS, Pandas, NumPy, SymPy, Vaex</p><p>**Areas of Expertise**: Machine Learning, Deep Learning, Reinforcement Learning, Motion Planning, Computer Vision, Control Systems</p><p>---</p><p>## üî≠ Research Interests</p><p>My research interests span motion planning, multi-agent systems, machine learning, and robotics. I'm particularly interested in developing efficient algorithms that can operate in real-time for practical robotic applications, including warehouse automation, hazardous environment operations, and multi-agent coordination.</p><p>---</p><p>## Research Statistics</p><p>- **Current GPA**: 4.0/4.0 (CMU)
- **Research Experience**: 2+ years
- **Industry Experience**: 1+ year</p></div></div><div class="grid grid-cols-1 md:grid-cols-3 gap-8 mt-16" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">3+</div><div class="text-lightSlate">Years Research Experience</div></div><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">5+</div><div class="text-lightSlate">Publications</div></div><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">10+</div><div class="text-lightSlate">Projects</div></div></div></div></div></section><section id="research" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Research Interests</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">My research focuses on motion planning, multi-agent systems, machine learning, and robotics, with emphasis on real-time algorithms for practical applications.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8 max-w-6xl mx-auto" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">ü§ñ</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Reinforcement Learning</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Develop algorithms that enable agents to learn close-to-optimal planning and control strategies in robotics, leveraging human demonstrations, fixed datasets, or interactions with dynamic environments.</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">üìà</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Sequence Modelling</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Design models that predict and understand sequential data, including temporal patterns, trajectories, and planning sequences.</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">üéØ</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Decision Making under Uncertainty</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Develop methods for robust and adaptive decision-making in partially observable or stochastic environments.</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">üë•</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Multi-Agent Reinforcement Learning (MARL)</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Study interactions of multiple agents learning together, including cooperation, competition, and strategic reasoning.</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">üõ°Ô∏è</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Safe and Robust Control</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Design control strategies for autonomous systems that ensure safety, reliability, and robustness under uncertainty.</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">üó∫Ô∏è</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Planning</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Develop algorithms for efficient and adaptive planning in robotics and AI systems, including long-horizon decision-making.</p></div></div></div></div></section><section id="publications" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Publications</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">My research contributions in multi-agent reinforcement learning, robotics, and AI systems.</p></div><div class="space-y-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Belief</h3><p class="text-lightSlate mb-3">Karan Mirakhor, Katia Sycara</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">ICLR<!-- --> <!-- -->2026</span></div><p class="text-lightSlate mt-4 leading-relaxed">We propose a novel approach to zero-shot coordination in multi-agent systems by leveraging belief modeling and opponent adaptation. Our method enables agents to coordinate effectively with unseen partners by maintaining beliefs about their strategies and adapting accordingly. The approach demonstrates significant improvements in cooperative environments with partial observability.</p></div><a href="https://openreview.net/forum?id=jJvXNpvOdM" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Strategic Deception in Multi-Agent Reinforcement Learning</h3><p class="text-lightSlate mb-3">Karan Mirakhor, Katia Sycara, Prashant Doshi</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">AAMAS<!-- --> <!-- -->2025</span></div><p class="text-lightSlate mt-4 leading-relaxed">This work explores the role of strategic deception in multi-agent reinforcement learning environments. We develop a framework for agents to learn when and how to deceive opponents while maintaining cooperation when beneficial. The approach shows improved performance in competitive scenarios with partial information.</p></div><a href="https://example.com/paper2" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Hierarchical Task Planning for Robotic Object Rearrangement under Partial Observability</h3><p class="text-lightSlate mb-3">Karan Mirakhor, TCS Research Team</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">ICRA<!-- --> <!-- -->2024</span></div><p class="text-lightSlate mt-4 leading-relaxed">We present a hierarchical approach to task planning for robotic object rearrangement in partially observable environments. The method combines high-level symbolic planning with low-level motion planning, enabling robots to handle uncertainty and adapt to changing environments. Experimental results show improved success rates in cluttered indoor scenarios.</p></div><a href="https://example.com/paper3" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div></div></div></section><section id="projects" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Projects</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">Selected projects showcasing my work in AI, robotics, and multi-agent systems.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Financial Market Prediction</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Developing a Finance-Informed Neural Network for predicting SPY S&amp;P 500 stock prices using time-series data. Leveraging FinBERT for advanced sentiment analysis of financial news, earnings reports, and market sentiment to improve prediction accuracy. This project combines deep learning techniques with financial domain knowledge to create more accurate market predictions.</p><a href="https://example.com/financial-market-prediction" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Formation Control and Multi-Agent Pathfinding (MAPF)</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Developed GIF-PIBT, a cutting-edge algorithm that integrates global formation heuristics with the Priority Inheritance with Backtracking (PIBT) framework to maintain agent formations while ensuring scalable, collision-free pathfinding. Developed a multi-resolution grid system and formation-maintenance heuristic using cost functions and transformations, optimizing transitions between formation-based and individual strategies in dynamic, obstacle-rich environments.</p><a href="https://example.com/formation-control-mapf" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">House Inspection Automation</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Developed a comprehensive image-processing pipeline leveraging classical and deep learning methods to detect structural damages such as rust, cracks, and wear in property images, enabling automated and reliable inspection reports. Engineered a modular system integrating semantic segmentation and contour-based algorithms for damage localization and classification, ensuring adaptability across diverse lighting and material conditions.</p><a href="https://example.com/house-inspection-automation" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Qualitative Analysis of RL Algorithms in Various Gym Environments</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Applied SARSA, Q-learning, and Dueling DQN across diverse environments, including Acrobot, Cartpole, and Taxi-v3. Leveraged advanced techniques like Monte-Carlo REINFORCE, SMDP-Q, and Dyna-Q in various gym environments. This project provided comprehensive analysis and comparison of different reinforcement learning algorithms across multiple benchmark environments.</p><a href="https://example.com/rl-algorithms-analysis" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div></div></div></section><section id="awards" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Awards &amp; Recognition</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">Recognition for academic excellence and research contributions.</p></div><div class="max-w-4xl mx-auto" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="relative"><div class="absolute left-8 top-0 bottom-0 w-0.5 bg-accent/30"></div><div class="space-y-8"><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Best Research Paper Award - TCS Research</h3><div class="text-accent font-medium mb-3">2024</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Recognized for outstanding contribution to robotic task planning research. The paper presented novel approaches to hierarchical planning under partial observability, with significant practical applications in service robotics.</p></div></div></div></div><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">JN Tata Endowment Scholarship</h3><div class="text-accent font-medium mb-3">2024</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Received for excellence in academic research and potential for doctoral study. This prestigious scholarship recognizes outstanding academic achievement and research potential in engineering and technology fields.</p></div></div></div></div><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Program Gold Medal - IIIT Hyderabad</h3><div class="text-accent font-medium mb-3">2023</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Awarded for achieving the highest GPA in the Electronics and Communication Engineering program. This recognition highlights academic excellence and outstanding performance throughout the undergraduate program.</p></div></div></div></div></div></div></div></div></section><section id="contact" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Get In Touch</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">I&#x27;m always interested in discussing new research opportunities, collaborations, and innovative projects in AI, robotics, and motion planning.</p></div><div class="max-w-4xl mx-auto" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6"><a href="mailto:karanmirakhor@gmail.com" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 4.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">Email</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">karanmirakhor@gmail.com</p></div></div></a><a href="https://scholar.google.com/citations?user=wpeFm64AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">Google Scholar</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">View Profile</p></div></div></a><a href="https://github.com/karan-13-hub" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">GitHub</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">karan-13-hub</p></div></div></a><a href="https://www.linkedin.com/in/karan-mirakhor-b065b7142/" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">LinkedIn</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Connect</p></div></div></a><a href="https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">CV</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Download</p></div></div></a></div><div class="text-center mt-12" style="opacity:0;transform:translateY(20px) translateZ(0)"><a href="mailto:gopalakt@andrew.cmu.edu" class="btn-primary text-lg px-8 py-4">Send me an email</a></div></div></div></section></main><footer class="bg-navy border-t border-lightestNavy"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="flex flex-col md:flex-row items-center justify-between space-y-4 md:space-y-0"><div class="text-lightSlate">¬© 2024 Gopalakrishnan Thirunellai Venkitachalam. All rights reserved.</div><div class="flex items-center space-x-6"><a href="https://scholar.google.com/citations?user=wpeFm64AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="Google Scholar"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg></a><a href="https://github.com/karan-13-hub" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="GitHub"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://www.linkedin.com/in/karan-mirakhor-b065b7142/" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="LinkedIn"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/","query":{},"buildId":"oCC-3wu0cex69U6BoWB_6","assetPrefix":"/karan-mirakhor","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>